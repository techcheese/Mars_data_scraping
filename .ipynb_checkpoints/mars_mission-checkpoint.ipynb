{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext black\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import requests\n",
    "import datetime\n",
    "#import selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_url = 'https://mars.nasa.gov/news/'\n",
    "jpl_root = 'https://www.jpl.nasa.gov'\n",
    "img_url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "twiter_url = 'https://twitter.com/marswxreport?lang=en'\n",
    "fact_url = 'https://space-facts.com/mars/'\n",
    "hemisphere_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latest Mars Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virginia Middle School Student Earns Honor of Naming NASA's Next Mars Rover\n",
      "NASA chose a seventh-grader from Virginia as winner of the agency's \"Name the Rover\" essay contest. Alexander Mather's entry for \"Perseverance\" was voted tops among 28,000 entries.\n"
     ]
    }
   ],
   "source": [
    "#open and parse the page\n",
    "news_soup = BeautifulSoup(requests.get(news_url).text, 'html.parser')\n",
    "\n",
    "#zip title and description items for iterability\n",
    "zipped = zip(\n",
    "    news_soup.find_all('div', class_='content_title'),\n",
    "    news_soup.find_all('div', class_='image_and_description_container')\n",
    "            )\n",
    "\n",
    "#loop though zip object and extract data\n",
    "articles = []\n",
    "for div in zipped:\n",
    "    info_dict = {\n",
    "    'article_title' : div[0].a.text.strip(),\n",
    "    'description_text' : div[1].text.strip(),\n",
    "    'article_link' : div[1].a['href'].strip(),\n",
    "    }\n",
    "    articles.append(info_dict)\n",
    "\n",
    "##grab the latest article\n",
    "latest_article_title = articles[0]['article_title']\n",
    "latest_article_desc = articles[0]['description_text']\n",
    "\n",
    "print(latest_article_title)\n",
    "print(latest_article_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Images from JPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Rose\n",
      "https://www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA14944_ip.jpg\n"
     ]
    }
   ],
   "source": [
    "#open and parse the page\n",
    "img_soup = BeautifulSoup(requests.get(img_url).text, 'html.parser')\n",
    "\n",
    "##start a list of featured images\n",
    "images = [] \n",
    "\n",
    "##get current featured image\n",
    "img_dict = {'feat_img_title' : (img_soup.find('div', class_='carousel_items').div.h1.text.strip()),\n",
    "           'feat_img_url' : jpl_root + str(img_soup.find('div', class_='carousel_items').div.footer.a.attrs['data-fancybox-href'])}\n",
    "\n",
    "##if its a new image, add to image list\n",
    "if img_dict not in images:\n",
    "    images.append(img_dict)\n",
    "\n",
    "##display latest image title and URL\n",
    "print(images[0]['feat_img_title'])\n",
    "print(images[0]['feat_img_url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is some weather data from Mars taken approximately at 2020-03-08 \n",
      "\n",
      "InSight sol 457 (2020-03-10) low -95.7ºC (-140.3ºF) high -9.1ºC (15.6ºF)\n",
      "winds from the SSE at 6.5 m/s (14.5 mph) gusting to 21.0 m/s (46.9 mph)\n",
      "pressure at 6.30 hPapic.twitter.com/2h0LKoSQrJ\n"
     ]
    }
   ],
   "source": [
    "twit_soup = BeautifulSoup(requests.get(twiter_url).text, 'html.parser')\n",
    "\n",
    "## the first tag contains the tweet and the \n",
    "## second tag contains the date it was posted\n",
    "tw_zip = zip(\n",
    "    twit_soup.find_all('div', class_=\"js-tweet-text-container\"), \n",
    "    twit_soup.find_all('span', class_=\"_timestamp js-short-timestamp\")\n",
    "            )\n",
    "\n",
    "weather = []\n",
    "\n",
    "##extract the data and add to weather if not already there\n",
    "for tweet in tw_zip:    \n",
    "    info_dict = {'tweet_text' : tweet[0].p.text,\n",
    "                'date' : datetime.date.fromtimestamp(int(tweet[1].attrs['data-time']))}\n",
    "    if info_dict['tweet_text'].startswith('InSight') and info_dict not in weather:\n",
    "        weather.append(info_dict)\n",
    "\n",
    "#grab latest tweet \n",
    "latest_weather_tweet = weather[0]['tweet_text']\n",
    "latest_weather_date = weather[0]['date']\n",
    "\n",
    "print(f\"Here is some weather data from Mars taken approximately at {latest_weather_date} \\n\\n\" +\n",
    "      f\"{latest_weather_tweet}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Equatorial Diameter:</td>\n",
       "      <td>6,792 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Polar Diameter:</td>\n",
       "      <td>6,752 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Mass:</td>\n",
       "      <td>6.39 × 10^23 kg (0.11 Earths)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Moons:</td>\n",
       "      <td>2 (Phobos &amp; Deimos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Orbit Distance:</td>\n",
       "      <td>227,943,824 km (1.38 AU)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Orbit Period:</td>\n",
       "      <td>687 days (1.9 years)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Surface Temperature:</td>\n",
       "      <td>-87 to -5 °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>First Record:</td>\n",
       "      <td>2nd millennium BC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Recorded By:</td>\n",
       "      <td>Egyptian astronomers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  1\n",
       "0                                                  \n",
       "Equatorial Diameter:                       6,792 km\n",
       "Polar Diameter:                            6,752 km\n",
       "Mass:                 6.39 × 10^23 kg (0.11 Earths)\n",
       "Moons:                          2 (Phobos & Deimos)\n",
       "Orbit Distance:            227,943,824 km (1.38 AU)\n",
       "Orbit Period:                  687 days (1.9 years)\n",
       "Surface Temperature:                   -87 to -5 °C\n",
       "First Record:                     2nd millennium BC\n",
       "Recorded By:                   Egyptian astronomers"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_soup = BeautifulSoup(requests.get(fact_url).text, 'html.parser')\n",
    "\n",
    "#:0 wow, extract tables with pandas\n",
    "facts_df = pd.DataFrame(pd.read_html(str(fact_soup))[0]).set_index(0)\n",
    "\n",
    "\n",
    "facts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'full_img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg',\n",
      "  'title': 'Cerberus Hemisphere Enhanced'},\n",
      " {'full_img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg',\n",
      "  'title': 'Schiaparelli Hemisphere Enhanced'},\n",
      " {'full_img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg',\n",
      "  'title': 'Syrtis Major Hemisphere Enhanced'},\n",
      " {'full_img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg',\n",
      "  'title': 'Valles Marineris Hemisphere Enhanced'}]\n"
     ]
    }
   ],
   "source": [
    "hemi_soup = BeautifulSoup(requests.get(hemisphere_url).text, 'html.parser')\n",
    "\n",
    "##this the root of the URL when it gets redirected to full image\n",
    "img_astrogeology_root = 'https://astropedia.astrogeology.usgs.gov'\n",
    "\n",
    "##found a way to get full img URLs without selenium because I was having\n",
    "## trouble with my virtualenv\n",
    "##would like to try with selenium\n",
    "hemispheres = []\n",
    "for hemi in hemi_soup.find_all('div', class_='item'):\n",
    "    info_dict = {\n",
    "        'title' : hemi.h3.text,\n",
    "        'full_img_url' : str(img_astrogeology_root + \n",
    "                       hemi.a['href'] + \n",
    "                       '.tif/full.jpg').replace('search/map', 'download')\n",
    "    }\n",
    "    hemispheres.append(info_dict)\n",
    "\n",
    "    \n",
    "pprint.pprint(hemispheres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zip object at 0x000002693B0E4048>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NavigableString' object has no attribute 'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-fa8924c00276>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     info_dict = {\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;34m'article_title'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mdiv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;34m'description_text'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mdiv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;34m'article_link'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mdiv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\.virtualenvs\\mars_data_scraping-si2resk6\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    869\u001b[0m             raise AttributeError(\n\u001b[0;32m    870\u001b[0m                 \"'%s' object has no attribute '%s'\" % (\n\u001b[1;32m--> 871\u001b[1;33m                     self.__class__.__name__, attr))\n\u001b[0m\u001b[0;32m    872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0moutput_ready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"minimal\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NavigableString' object has no attribute 'a'"
     ]
    }
   ],
   "source": [
    "\n",
    "news_soup = BeautifulSoup(requests.get(news_url).text, 'html.parser')\n",
    "\n",
    "#zip title and description items for iterability\n",
    "zipped = zip(\n",
    "    news_soup.find('div', class_='content_title'),\n",
    "    news_soup.find('div', class_='image_and_description_container')\n",
    "        )\n",
    "\n",
    "print(zipped)\n",
    "    \n",
    "info_dict = {\n",
    "'article_title' : zipped[1].a.text.strip(),\n",
    "'description_text' : zipped[1].text.strip(),\n",
    "'article_link' : zipped[1].a['href'].strip(),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
